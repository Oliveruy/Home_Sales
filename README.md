# Spark SQL Exercise: Analyzing Home Sales Data

## Purpose

The purpose of this exercise is to leverage SparkSQL to analyze key metrics about home sales data. Specifically, we will:

- Create temporary views
- Partition the data
- Cache and uncache a temporary table
- Verify that the table has been uncached

## Files

### 1. Home_Sales

This file contains the code to run the Spark SQL exercise locally. Ensure that the proper requirements are installed to run findspark and pyspark, as these are dependencies for the script.

### 2. home_Sales_colab

This file is intended for use in Google Colab. It imports the `_colab` file and executes the code. This can be useful if the requirements are not installed locally or if you prefer to run the code in a cloud-based environment.

## Instructions

1. Run the `Home_Sales` script locally to execute the Spark SQL exercise.
2. Alternatively, open the `Home_Sales_colab` file in Google Colab and execute the code.